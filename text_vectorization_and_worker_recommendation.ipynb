{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrBlL2DhTOVd9cjsTTr7fm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martians-sheep/pl_task_recomended_csd/blob/main/text_vectorization_and_worker_recommendation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# テキストのトークン数を確認する関数"
      ],
      "metadata": {
        "id": "nA9vOPWhSf_6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7L-61uVSdMC",
        "outputId": "4745cac5-f2b5-47b4-c806-4812c88944a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.6.0\n"
          ]
        }
      ],
      "source": [
        "# トークナイザーのインストール\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "def get_tokens(text):\n",
        "  # エンコーディングの取得\n",
        "  # embeddingで利用するモデルの\"text-embedding-ada-002\" の トークナイザーとして\"cl100k_base\"を利用する\n",
        "  enc = tiktoken.get_encoding(\"cl100k_base\")\n",
        "  # エンコードの実行\n",
        "  tokens = enc.encode(text)\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "Z8d1DG44StwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get_tokens関数の実行\n",
        "tokens = get_tokens(\"こんにちは、世界！\")\n",
        "print(len(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTnIKCnFTeHU",
        "outputId": "ca041b40-423e-4f64-e6e5-9925d0699086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# サンプルデータのファイルパスを返す関数"
      ],
      "metadata": {
        "id": "O3VQnRHyTrH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Google Driveをマウントする\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 起点となるフォルダのパスを指定する\n",
        "base_folder = '/content/drive/MyDrive/{サンプルデータのフォルダ名}'\n",
        "\n",
        "def get_file_paths(folder_path):\n",
        "    file_paths = []\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            if file.endswith('.txt'):  # テキストファイルのみ処理する\n",
        "                file_path = os.path.join(root, file)\n",
        "                file_paths.append(file_path)\n",
        "    return file_paths"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmkxlY2JThPC",
        "outputId": "c27ce941-220e-4744-d49f-8699d517313a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get_file_paths関数の実行\n",
        "file_paths = get_file_paths(base_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "VATnLHE1T8yZ",
        "outputId": "2b47b2ea-4a1d-4feb-978a-8a84585f8099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'get_file_paths' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-ba5bf2907751>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get_file_paths関数の実行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfile_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_file_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'get_file_paths' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ファイルパスを元にテキストのトークン数を確認する"
      ],
      "metadata": {
        "id": "0BPhugyTUO90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ファイルパスからテキストを取得する関数\n",
        "def get_file_content(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            content = file.read()\n",
        "            return content\n",
        "    except IOError:\n",
        "        print(f\"ファイル {file_path} の読み込み中にエラーが発生しました。\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "ZwvLUNH6Uzrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ファイルパスのリストをトークン数制限に基づいてグループ化する関数\n",
        "# 一度に扱えるtoken数が8000であるため8000毎にグループ化する\n",
        "# todo　： クソデカファイルの扱い\n",
        "def split_files_by_token_count(file_paths, max_tokens=8000):\n",
        "    file_path_groups = []\n",
        "    current_group = []\n",
        "    current_token_count = 0\n",
        "\n",
        "    for file_path in file_paths:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            text = file.read()\n",
        "            token_count = len(get_tokens(text))\n",
        "\n",
        "            if current_token_count + token_count <= max_tokens:\n",
        "                current_group.append(file_path)\n",
        "                current_token_count += token_count\n",
        "            else:\n",
        "                file_path_groups.append(current_group)\n",
        "                current_group = [file_path]\n",
        "                current_token_count = token_count\n",
        "\n",
        "    if current_group:\n",
        "        file_path_groups.append(current_group)\n",
        "\n",
        "    return file_path_groups"
      ],
      "metadata": {
        "id": "OzDxMRr5VHi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split_files_by_token_count関数の実行\n",
        "file_path_groups = split_files_by_token_count(file_paths)\n",
        "# グループ数\n",
        "print(len(file_path_groups))"
      ],
      "metadata": {
        "id": "58mRhS3DVZGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CSVファイルとして作業実施者と作業済みファイルのデータの作成"
      ],
      "metadata": {
        "id": "qsnpkf6dVuXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import random\n",
        "\n",
        "# 作業実施者と作業済みファイルを紐付けたCSVを作成する\n",
        "# ここでは作業実施者は5名を想定\n",
        "def assign_file_info(file_paths, csv_file):\n",
        "    # CSVファイルが存在しない場合は新規作成し、ヘッダーを書き込む\n",
        "    if not os.path.exists(csv_file):\n",
        "        with open(csv_file, mode='w', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow(['index', 'file_path', 'worker_id'])\n",
        "\n",
        "    # 既存のCSVファイルからデータを読み込む\n",
        "    existing_data = []\n",
        "    if os.path.exists(csv_file):\n",
        "        with open(csv_file, mode='r') as file:\n",
        "            reader = csv.reader(file)\n",
        "            next(reader)  # ヘッダーをスキップ\n",
        "            existing_data = list(reader)\n",
        "\n",
        "    # worker_idごとの優先ファイルパスの設定\n",
        "    priority_paths = {\n",
        "        1: 'IT',\n",
        "        2: 'houmu',\n",
        "        3: 'qa',\n",
        "        4: 'quality',\n",
        "        5: 'r_and_d'\n",
        "    }\n",
        "\n",
        "    # 新しいデータを生成\n",
        "    new_data = []\n",
        "    for file_path in file_paths:\n",
        "        index = len(existing_data) + len(new_data)\n",
        "\n",
        "        # 優先ファイルパスに基づいてworker_idを割り当て\n",
        "        assigned_worker_id = None\n",
        "        for worker_id, priority_path in priority_paths.items():\n",
        "            if priority_path in file_path:\n",
        "                if random.random() < 0.8:  # 80%の確率で優先割り当て\n",
        "                    assigned_worker_id = worker_id\n",
        "                    break\n",
        "\n",
        "        # 優先割り当てされなかった場合はランダムにworker_idを割り当て\n",
        "        if assigned_worker_id is None:\n",
        "            assigned_worker_id = random.randint(1, 5)\n",
        "\n",
        "        new_data.append([index, file_path, assigned_worker_id])\n",
        "\n",
        "           # 新しいデータをCSVファイルに追記\n",
        "    with open(csv_file, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerows(new_data)\n",
        "\n",
        "    print(f\"Assigned {len(new_data)} files to workers.\")"
      ],
      "metadata": {
        "id": "nohZ-av_VhXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CSVファイルのファイルパス\n",
        "csv_file = \"./worked_files.csv\"\n",
        "# CSVファイルの作成\n",
        "assign_file_info(file_paths, csv_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "EwLgiWeQWEhE",
        "outputId": "94a5d9dd-51db-4f42-879e-d3f61689d13e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'file_paths' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-238daea42528>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcsv_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./worked_files.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0massign_file_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'file_paths' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# フォルダごとに割り当てられた担当者の割合を出す関数\n",
        "from collections import defaultdict\n",
        "\n",
        "def analyze_worker_distribution(csv_file):\n",
        "    # フォルダごとの担当者の割合を格納する辞書\n",
        "    folder_worker_distribution = {\n",
        "        'IT': defaultdict(int),\n",
        "        'houmu': defaultdict(int),\n",
        "        'qa': defaultdict(int),\n",
        "        'quality': defaultdict(int),\n",
        "        'r_and_d': defaultdict(int)\n",
        "    }\n",
        "\n",
        "    # CSVファイルからデータを読み込む\n",
        "    with open(csv_file, mode='r') as file:\n",
        "        reader = csv.reader(file)\n",
        "        next(reader)  # ヘッダーをスキップ\n",
        "\n",
        "        # 各行を処理\n",
        "        for row in reader:\n",
        "            file_path = row[1]\n",
        "            worker_id = int(row[2])\n",
        "\n",
        "            # フォルダごとに担当者の割合を集計\n",
        "            for folder in folder_worker_distribution.keys():\n",
        "                if folder in file_path:\n",
        "                    folder_worker_distribution[folder][worker_id] += 1\n",
        "                    break\n",
        "\n",
        "    # 割合を計算して表示\n",
        "    for folder, worker_counts in folder_worker_distribution.items():\n",
        "        total_files = sum(worker_counts.values())\n",
        "        if total_files > 0:\n",
        "            print(f\"Folder: {folder}\")\n",
        "            for worker_id, count in worker_counts.items():\n",
        "                percentage = count / total_files * 100\n",
        "                print(f\"  Worker {worker_id}: {percentage:.2f}%\")\n",
        "        else:\n",
        "            print(f\"Folder: {folder}\")\n",
        "            print(\"  No files assigned.\")\n",
        "        print()"
      ],
      "metadata": {
        "id": "Fqb7SjMEWK2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# フォルダ毎に割り当てられた人の割合を確認する\n",
        "analyze_worker_distribution(csv_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "0UV42cWzWX-P",
        "outputId": "da49f4aa-73a2-4bcc-e1aa-f36730a8d27f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'analyze_worker_distribution' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-3c998b2bc74b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manalyze_worker_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'analyze_worker_distribution' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# テキストデータのベクトル化(Embedding)"
      ],
      "metadata": {
        "id": "qsVkTyHsW3Gt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI のライブラリをインストール\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUwpsfkWWZsb",
        "outputId": "6686d635-13d0-4455-fbc7-0d02a23211a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.14.3-py3-none-any.whl (262 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/262.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m225.3/262.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.9/262.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.14.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "# OpenAI のAPIキーを取得\n",
        "# ※環境変数としてOpenAIのAPIキーを設定してください\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "# クライアントの準備\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "tCnCHcacW_2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "# テキストデータのベクトル化(embedding)関数\n",
        "def get_embeddings(texts: List[str]) -> List[List[float]]:\n",
        "\n",
        "  response = client.embeddings.create(\n",
        "    input=texts,\n",
        "    model=\"text-embedding-ada-002\"\n",
        " )\n",
        "  return response"
      ],
      "metadata": {
        "id": "mbk7xjmOXPvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ファイルパスからファイルを取得する\n",
        "def get_file_contents(file_paths):\n",
        "    file_contents = []\n",
        "    for path in file_paths:\n",
        "        try:\n",
        "            with open(path, 'r') as file:\n",
        "                content = file.read()\n",
        "                file_contents.append(content)\n",
        "        except IOError:\n",
        "            print(f\"ファイル {path} の読み込み中にエラーが発生しました。\")\n",
        "    return file_contents"
      ],
      "metadata": {
        "id": "melnMOIbXY5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ファイルパスのリストを受け取り、\n",
        "# 各ファイルの内容からOpenAIのAPIを使用して埋め込みベクトルを取得し、\n",
        "# 全ファイルの埋め込みベクトルをリストで返す関数\n",
        "def get_all_embeddings(filePaths):\n",
        "  embeddings = []\n",
        "  for filePath in filePaths:\n",
        "    # 8000トークン以内のテキストコンテンツの取得\n",
        "    file_contents = get_file_contents(filePath)\n",
        "    # embeddingの実行\n",
        "    response = get_embeddings(file_contents)\n",
        "    batch_embeddings = [record.embedding for record in response.data]\n",
        "    # ベクトルデータをまとめる\n",
        "    embeddings.extend(batch_embeddings)\n",
        "  return embeddings"
      ],
      "metadata": {
        "id": "g5URkEwLXxW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# npyファイルとして保存する関数\n",
        "def save_embeddings(embeddings, file_path):\n",
        "    np.save(file_path, embeddings)"
      ],
      "metadata": {
        "id": "kvRLeYFvbaBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy配列に変換\n",
        "target_embeds = get_all_embeddings(file_path_groups)\n",
        "target_embeds = np.array(target_embeds).astype(\"float32\")\n",
        "\n",
        "# Embeddingを保存\n",
        "save_embeddings(target_embeds,\"embeddings_all.npy\")"
      ],
      "metadata": {
        "id": "V15uuifTbhy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ベクトルデータベースへのIndex登録\n"
      ],
      "metadata": {
        "id": "OO9WQFFCb1DO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Faissパッケージのインストール\n",
        "!pip install faiss-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iru2ocaLcKrc",
        "outputId": "9c9ca398-4603-4e6d-861d-38c6119dd061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ベクトルデータのファイルパス\n",
        "embedding_file =  './embeddings_all.npy'"
      ],
      "metadata": {
        "id": "roid_3zycNGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ファイルからEmbeddingを読み込む\n",
        "target_embeds = np.load(embedding_file)\n",
        "\n",
        "# インデックス数の取得\n",
        "d = target_embeds.shape[1]\n",
        "print(d)\n",
        "\n",
        "# Faissのインデックス生成\n",
        "# ここで利用している検索アルゴリズムはIndexFlatL2(L2ノルム)で、ユークリッド距離を使用してベクトル間の類似を計算する\n",
        "# 他にも IndexFlatIP(コサイン類似度）、IndexIVFFlat(高速化アルゴリズム)を利用可能\n",
        "index = faiss.IndexFlatL2(d)\n",
        "\n",
        "# 対象テキストをインデックスに追加\n",
        "index.add(target_embeds)"
      ],
      "metadata": {
        "id": "RIS_R4okcV53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 作業対象のファイルを読み込み、作業候補者を出す"
      ],
      "metadata": {
        "id": "acSpk4QddFUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# テキストを読み込む\n",
        "txt_file_path = \"./{作業対象のファイル}.txt\"\n",
        "\n",
        "with open(txt_file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    in_text = file.read()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "itu3CF8Hc_tj",
        "outputId": "b448a62c-eb40-41c8-94ed-fddbdbd2348f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './{作業対象のファイル}.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-64fe7e166e4b>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtxt_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./{作業対象のファイル}.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0min_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './{作業対象のファイル}.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 作業対象のファイルをベクトル化する\n",
        "response =client.embeddings.create(\n",
        "    input=in_text,\n",
        "    model=\"text-embedding-ada-002\"\n",
        ")\n",
        "\n",
        "# ベクトル化したデータをnumpy配列に変換\n",
        "in_embeds = [record.embedding for record in response.data]\n",
        "in_embeds = np.array(in_embeds).astype(\"float32\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "PtjQi0YgdR_q",
        "outputId": "05b71daf-8cda-4b0f-f91e-09b6e2034327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'client' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-37e8fd976d99>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 作業対象のファイルをベクトル化する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m response =client.embeddings.create(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-embedding-ada-002\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# 作業推薦者を割り出す関数\n",
        "def recommend_workers(query_embedding, csv_file, index, k=10):\n",
        "    # 近傍探索の実行\n",
        "    D, I = index.search(query_embedding, k)\n",
        "    print(D)\n",
        "    print(I)\n",
        "\n",
        "    # 類似ファイルのインデックス値を取得\n",
        "    similar_indices = I[0].tolist()\n",
        "\n",
        "    # CSVファイルから既存のファイルパスと担当者IDを読み込む\n",
        "    file_paths = []\n",
        "    worker_ids = []\n",
        "    with open(csv_file, mode='r') as file:\n",
        "        reader = csv.reader(file)\n",
        "        next(reader)  # ヘッダーをスキップ\n",
        "        for row in reader:\n",
        "            file_paths.append(row[1])\n",
        "            worker_ids.append(int(row[2]))\n",
        "\n",
        "    # 類似ファイルの担当者IDを取得\n",
        "    similar_worker_ids = [worker_ids[i] for i in similar_indices]\n",
        "\n",
        "    # 担当者IDの出現回数をカウント\n",
        "    worker_id_counts = {}\n",
        "    for worker_id in similar_worker_ids:\n",
        "        worker_id_counts[worker_id] = worker_id_counts.get(worker_id, 0) + 1\n",
        "\n",
        "    # 出現回数の多い順に担当者IDを取得\n",
        "    sorted_worker_ids = sorted(worker_id_counts, key=worker_id_counts.get, reverse=True)\n",
        "\n",
        "    # 推薦する作業担当者のIDを取得\n",
        "    recommended_worker_ids = sorted_worker_ids[:3]  # 上位3人を推薦\n",
        "\n",
        "    return recommended_worker_ids"
      ],
      "metadata": {
        "id": "5nf_mQLAdUGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 作業候補者を出す関数の実行\n",
        "recommended_worker_ids = recommend_workers(in_embeds, csv_file, index)\n",
        "\n",
        "# 例えば以下のような形で出力される 上からベクトルの距離、類似ファイルのインデックス、推薦された作業者ID\n",
        "# [[0.03189817 0.04887741 0.08837742 0.11160477 0.13243756 0.1446165 0.18959308 0.22103558 0.24178305 0.25575137]]\n",
        "# [[458 459 475 492 487 483 484 497 462 469]]\n",
        "# Recommended worker IDs: [5, 3, 4]\n",
        "\n",
        "print(\"Recommended worker IDs:\", recommended_worker_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "KoDRzsfBdgG1",
        "outputId": "0cab8760-a68e-4a44-92bc-c509c82179ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'recommend_workers' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-f01f9aa0f439>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 作業候補者を出す関数の実行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrecommended_worker_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecommend_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recommended worker IDs:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecommended_worker_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'recommend_workers' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "okxRLBQXdxXu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}